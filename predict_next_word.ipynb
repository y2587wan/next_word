{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict_next_word.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9J7VEM_8fT6",
        "colab_type": "text"
      },
      "source": [
        "Data from https://www.kaggle.com/aashita/nyt-comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yabQnQsc8lrP",
        "colab_type": "code",
        "outputId": "73e5fe86-a1b9-4d85-fe5e-62e8f740d084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "!unzip 19447_31436_bundle_archive.zip -d input"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  19447_31436_bundle_archive.zip\n",
            "  inflating: input/ArticlesApril2017.csv  \n",
            "  inflating: input/ArticlesApril2018.csv  \n",
            "  inflating: input/ArticlesFeb2017.csv  \n",
            "  inflating: input/ArticlesFeb2018.csv  \n",
            "  inflating: input/ArticlesJan2017.csv  \n",
            "  inflating: input/ArticlesJan2018.csv  \n",
            "  inflating: input/ArticlesMarch2017.csv  \n",
            "  inflating: input/ArticlesMarch2018.csv  \n",
            "  inflating: input/ArticlesMay2017.csv  \n",
            "  inflating: input/CommentsApril2017.csv  \n",
            "  inflating: input/CommentsApril2018.csv  \n",
            "  inflating: input/CommentsFeb2017.csv  \n",
            "  inflating: input/CommentsFeb2018.csv  \n",
            "  inflating: input/CommentsJan2017.csv  \n",
            "  inflating: input/CommentsJan2018.csv  \n",
            "  inflating: input/CommentsMarch2017.csv  \n",
            "  inflating: input/CommentsMarch2018.csv  \n",
            "  inflating: input/CommentsMay2017.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccAdoykxBusH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow.keras.utils as ku \n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import string, os\n",
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhfSCe8zSEGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/nnlm-en-dim128/2\"\n",
        "embed = hub.KerasLayer(module_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VtKZKFiFnqO",
        "colab_type": "code",
        "outputId": "697cc119-712f-40f8-c938-e4a65d1600e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip 19447_31436_bundle_archive.zip -d input"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  19447_31436_bundle_archive.zip\n",
            "replace input/ArticlesApril2017.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKYxXbR3MbrP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0033f8b2-d9b5-4910-f26d-7891815976e5"
      },
      "source": [
        "curr_dir = 'input/'\n",
        "all_headlines = []\n",
        "for filename in os.listdir(curr_dir):\n",
        "    if 'Articles' in filename:\n",
        "        article_df = pd.read_csv(curr_dir + filename)\n",
        "        all_headlines.extend(list(article_df.headline.values))\n",
        "\n",
        "all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n",
        "len(all_headlines)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8603"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWdEZSesMiBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "5caead0f-63d4-49d8-a550-5f3a8530fe3b"
      },
      "source": [
        "def clean_text(txt):\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
        "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return txt \n",
        "\n",
        "corpus = [clean_text(x) for x in all_headlines]\n",
        "corpus[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my beijing the sacred city',\n",
              " '6 million riders a day 1930s technology',\n",
              " 'seeking a crossborder conference',\n",
              " 'questions for despite the yuck factor leeches are big in russian medicine',\n",
              " 'who is a criminal',\n",
              " 'an antidote to europes populism',\n",
              " 'the cost of a speech',\n",
              " 'degradation of the language',\n",
              " 'on the power of being awful',\n",
              " 'trump garbles pitch on a revised health bill']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyFAJIgzYazP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5672772-236c-49c0-96d9-031e0801336f"
      },
      "source": [
        "embed([corpus[0]])\n",
        "corpus[0].split()[-1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'city'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgWZHIqtMmO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9cdeddc-e9fd-4aba-fc74-6eaf7c433a5f"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "def get_embd(corpus):\n",
        "  #sequence\n",
        "  xs = []\n",
        "  xss = []\n",
        "  for line in corpus:\n",
        "    words = line.split()\n",
        "    for i in range(0, len(words) - 1):\n",
        "      xs.append(\" \".join(words[0:i+1]))\n",
        "      xss.append([xs[-1]])\n",
        "  return embed(xs), np.array(xss)\n",
        "x, xs = get_embd(corpus)\n",
        "\n",
        "\n",
        "def get_sequence_of_tokens(corpus):\n",
        "    ## tokenization\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    \n",
        "    ## convert data to sequence of tokens \n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "        \n",
        "    return input_sequences, total_words\n",
        "\n",
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = ku.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n",
        "\n",
        "print(x.shape, len(label))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(51770, 128) 51770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYgRh5UVywHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXpf7yjiMvSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "1228d162-2d4e-465d-8f9c-da041ecebe7b"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dense(total_words, activation = 'softmax'))\n",
        "model.compile(loss='categorical_crossentropy',  optimizer='adam')\n",
        "model.build(x.shape)\n",
        "model.summary()\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_31 (Dense)             multiple                  33024     \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             multiple                  2895105   \n",
            "=================================================================\n",
            "Total params: 2,928,129\n",
            "Trainable params: 2,928,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f29F5zk_uZ-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "6565315f-9a66-4606-d400-fc4bb83fbd82"
      },
      "source": [
        "import tensorflow as tf\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "model.fit(x, label, epochs=10, validation_split=0.1,  shuffle=True, batch_size=32, callbacks=[callback])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1457/1457 [==============================] - 9s 6ms/step - loss: 7.7923 - val_loss: 7.5980\n",
            "Epoch 2/10\n",
            "1457/1457 [==============================] - 8s 6ms/step - loss: 6.8926 - val_loss: 7.6113\n",
            "Epoch 3/10\n",
            "1457/1457 [==============================] - 8s 6ms/step - loss: 6.3374 - val_loss: 7.6820\n",
            "Epoch 4/10\n",
            "1457/1457 [==============================] - 8s 6ms/step - loss: 5.6799 - val_loss: 8.0485\n",
            "Epoch 5/10\n",
            "1457/1457 [==============================] - 8s 6ms/step - loss: 4.8429 - val_loss: 8.7118\n",
            "Epoch 6/10\n",
            "1457/1457 [==============================] - 8s 6ms/step - loss: 4.0534 - val_loss: 9.2954\n",
            "Epoch 7/10\n",
            "1457/1457 [==============================] - 8s 6ms/step - loss: 3.5645 - val_loss: 9.7521\n",
            "Epoch 8/10\n",
            "1457/1457 [==============================] - 8s 6ms/step - loss: 3.2646 - val_loss: 10.1491\n",
            "Epoch 9/10\n",
            "1457/1457 [==============================] - 8s 6ms/step - loss: 3.0534 - val_loss: 10.4846\n",
            "Epoch 10/10\n",
            "1457/1457 [==============================] - 9s 6ms/step - loss: 2.8885 - val_loss: 10.8178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0508c85588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOU-45A7ScXz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f26e64e-91cc-422b-d1f0-2d106dc97955"
      },
      "source": [
        "def predict(model, sentence):\n",
        "  predicted = model.predict_classes(embed([sentence]), verbose=0)\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "      if index == predicted[0]:\n",
        "          output_word = word\n",
        "          print(output_word)\n",
        "          break\n",
        "\n",
        "predict(model, \"What is the craziest\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6FY163CMzdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('my_model.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TriO1_cZ9_wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nR9UFVP95CV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4472db06-b8c2-4682-f88c-e9a498475fc6"
      },
      "source": [
        "m = load_model(\"my_model.h5\")\n",
        "predict(m, \"space\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "and\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}